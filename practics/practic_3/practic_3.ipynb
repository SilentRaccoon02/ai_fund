{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интерфейсы scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, OneToOneFeatureMixin\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../../config.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator\n",
    "\n",
    "Для примера построим простой estimator, который в перспективе будет вычитать из признаков их среднее значение и после сдвигать признаки на заранее заданную константу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubtractMeanAndShiftEstimator(BaseEstimator):\n",
    "    def __init__(self, shift=0.0):\n",
    "        self.shift: float = shift\n",
    "        self.means_: NDArray = (\n",
    "            None  # we add a trailing underscore for parameters which will be learnt in fit()\n",
    "        )\n",
    "\n",
    "    def fit(self, X: NDArray, y: NDArray = None):\n",
    "        # y is ignored here\n",
    "        self.means_ = X.mean(axis=0)  # the first axis corresponds to samples by default\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SubtractMeanAndShiftEstimator(shift=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `get_params()` реализован в `BaseEstimator`, и мы можем сразу использовать его для получения гиперпараметров модели. Это возможно, так как единственный гиперпараметр `shift` был передан как явное ключевое слово в контрукторе\n",
    "\n",
    "Обратите внимание, что соответствующий аттрибут класса должен совпадать с ключевым словом: `self.shift = shift`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично мы можем использовать `set_params()` для задания значений гиперпараметров. Этот метод пригодится при поиске оптимальных значений гиперпараметров\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.set_params(shift=5)\n",
    "m.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [1, 10],\n",
    "        [3, 30],\n",
    "        [2, 20],\n",
    "    ]\n",
    ")\n",
    "y = np.array(\n",
    "    [\n",
    "        [0, -8],\n",
    "        [2, 10],\n",
    "        [1, 1],\n",
    "    ]\n",
    ")\n",
    "m.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn есть класс sklearn.base.OutlierMixin, который позволяет реализовывать кастомные классы для определения выбросов.\n",
    "Он добавляет:\n",
    "\n",
    "-   атрибут \\_estimator_type, по умолчанию outlier_detector\n",
    "-   fit_predict.\n",
    "\n",
    "Метод fit() работает в формате без учителя, predict же должен классифицировать данные на аутлаеры (возвращать для них -1) и обыычные данные (возвращать 1). Для классификации используется отсечка по порогу предсказаний, полученных внутренним.\n",
    "Во встроенных методах функция оценки доступна с помощью метода `score_samples`, в то время как порог можно задать параметром `contamination`.\n",
    "Например, для гауссовских данных можно использовать sklearn.covariance.EllipticEnvelope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте свой эстиматор с использованием sklearn.base.OutlierMixin, который будет определять выбросы на основе интерквартильного размаха.\n",
    "Он должен возвращать один столбец с 1 и -1, а также позволять задавать порог для квантиля, определяющего размах. Не забудьте, что он должен быть двухсторонним.\n",
    "Ваш эстиматор должен работать и для датафреймов, и для numpy массивов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, OutlierMixin\n",
    "\n",
    "\n",
    "class MyEstimator(BaseEstimator, OutlierMixin):\n",
    "    def __init__(self, factor=1.5):\n",
    "        self.factor = factor\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted_ = True\n",
    "        X = pd.DataFrame(X.copy())\n",
    "        q1 = X.quantile(0.35)\n",
    "        q3 = X.quantile(0.55)\n",
    "        iqr = q3 - q1\n",
    "        self._lower_bound = q1 - (self.factor * iqr)\n",
    "        self._upper_bound = q3 + (self.factor * iqr)\n",
    "        print(X.min(axis=0))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        temp = np.ones(len(X))\n",
    "        temp[\n",
    "            (X > self._lower_bound.values).all(axis=1)\n",
    "            & (X < self._upper_bound.values).all(axis=1)\n",
    "        ] = -1\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MyEstimator()\n",
    "true_cov = np.array([[0.8, 0.3], [0.3, 0.4]])\n",
    "X = np.random.RandomState(42).multivariate_normal(mean=[0, 0], cov=true_cov, size=500)\n",
    "e = estimator.fit(X)\n",
    "# pred = estimator.predict(X)\n",
    "e._lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e._upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor\n",
    "\n",
    "Рассмотрим тот же класс, но добавим к нему методы `predict()` и `score()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubtractMeanAndShiftPredictor(BaseEstimator):\n",
    "    def __init__(self, shift=0.0):\n",
    "        self.shift: float = shift\n",
    "        self.means_: NDArray = (\n",
    "            None  # we add a trailing underscore for parameters which will be learnt in fit()\n",
    "        )\n",
    "\n",
    "    def fit(self, X: NDArray, y: NDArray = None):\n",
    "        # y is ignored here\n",
    "        self.means_ = X.mean(axis=0)  # the first axis corresponds to samples by default\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: NDArray) -> NDArray:\n",
    "        e = np.ones((X.shape[0], 1))\n",
    "        return X - e @ self.means_.reshape(-1, 1).T + self.shift\n",
    "\n",
    "    def score(self, X: NDArray, y: NDArray) -> float:\n",
    "        return r2_score(\n",
    "            y, self.predict(X)\n",
    "        )  # R2 \\in (-\\infty; 1] is the coefficient of determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы специально добавили небольшое отклонение в y, наш R2 чуть меньше 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SubtractMeanAndShiftPredictor(shift=1)\n",
    "model.fit(X)\n",
    "model.predict(X)\n",
    "# model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n",
    "Рассмотрим тот же класс, но добавим к нему метод `transform()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubtractMeanAndShiftTransformer(\n",
    "    BaseEstimator, OneToOneFeatureMixin, TransformerMixin\n",
    "):\n",
    "\n",
    "    def __init__(self, shift=0.0):\n",
    "        self.shift: float = shift\n",
    "        self.means_: NDArray = (\n",
    "            None  # we add a trailing underscore for parameters which will be learnt in fit()\n",
    "        )\n",
    "\n",
    "    def fit(self, X: NDArray, y: NDArray = None):\n",
    "        # y is ignored here\n",
    "        self.means_ = X.mean(axis=0)  # the first axis corresponds to samples by default\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: NDArray) -> NDArray:\n",
    "        e = np.ones((X.shape[0], 1))\n",
    "        return X - e @ self.means_.reshape(-1, 1).T + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = SubtractMeanAndShiftTransformer(shift=5)\n",
    "t.fit(X)\n",
    "t.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы добавили `TransformerMixin`, мы можем использовать метод `fit_transform()`, не реализуя его явно\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично мы можем использовать метод `get_feature_names_out()`, так как мы добавили `OneToOneFeatureMixin`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.get_feature_names_out(input_features=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем датасет с домами как пример. Вспомним, что мы делали в прошлый раз, и попробуем заполнить пропущенные значения в некоторых числовых столбцах.\n",
    "Для этого используем трансформер по столбцам.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(cfg[\"house_prices\"][\"train_dataset\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию, только указанные столбцы трансформируются и возвращаются (remainder=`drop`). Мы же сделаем так, чтобы все остальные столбцы тоже возвращались, просто с ними бы ничего не делалось.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            \"mean_impute\",\n",
    "            SimpleImputer(strategy=\"mean\"),\n",
    "            [\"SalePrice\", \"LotArea\", \"WoodDeckSF\", \"MasVnrArea\"],\n",
    "        )\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "ct.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у датасета появятсся столбцы, которые не были представлены во время fit (даже среди тех, что не трансформировались), то они будут выкинуты на этапе transform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"temp\"] = 0\n",
    "ct.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Перейдите к медианному заполнению пропусков. Проверьте, что результаты, полученные с помощью трансформации, соответствуют преобразованию напрямую.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            \"median_impute\",\n",
    "            SimpleImputer(strategy=\"median\"),\n",
    "            [\"SalePrice\", \"LotArea\", \"WoodDeckSF\", \"MasVnrArea\"],\n",
    "        )\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "ct.set_output(transform=\"pandas\")\n",
    "df_transform = ct.fit_transform(df)\n",
    "\n",
    "df_copy = df.copy()\n",
    "numeric_cols = [\"SalePrice\", \"LotArea\", \"WoodDeckSF\", \"MasVnrArea\"]\n",
    "df_copy[numeric_cols] = df_copy[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "df_transform = df_transform[df_copy.columns]\n",
    "\n",
    "print(df_transform.index.equals(df_copy.index))\n",
    "print(df_transform.columns.equals(df_copy.columns))\n",
    "\n",
    "df_transform.loc[0, \"Id\"] = 10\n",
    "diff = df_transform.compare(df_copy)\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Добавьте еще нормализатор для LotFrontage, LotArea и запустите в ColumnTransformer. Обучите его и примените.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            \"median_impute\",\n",
    "            SimpleImputer(strategy=\"median\"),\n",
    "            [\"SalePrice\", \"LotArea\", \"WoodDeckSF\", \"MasVnrArea\"],\n",
    "        ),\n",
    "        (\"normalize\", StandardScaler(), [\"LotFrontage\", \"LotArea\"]),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=True,\n",
    ")\n",
    "\n",
    "ct.set_output(transform=\"pandas\")\n",
    "df_transform = ct.fit_transform(df)\n",
    "\n",
    "df_copy = df.copy()\n",
    "df_copy[\n",
    "    [\n",
    "        \"median_impute__SalePrice\",\n",
    "        \"median_impute__LotArea\",\n",
    "        \"median_impute__WoodDeckSF\",\n",
    "        \"median_impute__MasVnrArea\",\n",
    "    ]\n",
    "] = df_copy[[\"SalePrice\", \"LotArea\", \"WoodDeckSF\", \"MasVnrArea\"]].fillna(\n",
    "    df[[\"SalePrice\", \"LotArea\", \"WoodDeckSF\", \"MasVnrArea\"]].median()\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_copy[[\"normalize__LotFrontage\", \"normalize__LotArea\"]] = scaler.fit_transform(\n",
    "    df_copy[[\"LotFrontage\", \"LotArea\"]]\n",
    ")\n",
    "\n",
    "to_change = [\"SalePrice\", \"LotArea\", \"WoodDeckSF\", \"MasVnrArea\", \"LotFrontage\"]\n",
    "to_remain = [col for col in df.columns if col not in to_change]\n",
    "df_copy[[f\"remainder__{col}\" for col in to_remain]] = df_copy[to_remain]\n",
    "df_copy = df_copy.drop(df.columns, axis=1)\n",
    "\n",
    "print(df_transform.index.equals(df_copy.index))\n",
    "print(df_transform.columns.equals(df_copy.columns))\n",
    "\n",
    "df_transform = df_transform.astype(df_copy.dtypes)\n",
    "print(df_transform.equals(df_copy))\n",
    "\n",
    "df_transform = df_transform[df_copy.columns]\n",
    "df_transform.loc[0, \"Id\"] = 10\n",
    "print(df_transform.equals(df_copy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn располагает большим количеством встроенных трансформеров. Соответствующие трансформеры есть и для категориальных фичей (более подробно рассмотрим этот тип чуть позже). Например, известное нам бинарное кодирование можно проводить с помощью OneHotEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"median_impute\",\n",
    "            SimpleImputer(strategy=\"mean\"),\n",
    "            [\"SalePrice\", \"LotArea\", \"WoodDeckSF\", \"MasVnrArea\"],\n",
    "        ),\n",
    "        (\n",
    "            \"one_hot_encode\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "            [\"MSZoning\", \"SaleType\", \"SaleCondition\"],\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "ct.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.set_output(transform=\"pandas\")\n",
    "ct.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выбора столбцов можно создавать make_selector, например, по выбору численных и категориальных значений.\n",
    "\n",
    "**Доп. задание**. Сделайте трансформер для OneHotEncoder на основе make_selector так, чтобы выбирать все нечисловые столбцы. Сколько столбцов получается после трансформации?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "С помощью Pipeline мы можем производить последовательную обработку данных и выполнять предсказание в конце\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [1, 10],\n",
    "        [3, 30],\n",
    "        [2, 20],\n",
    "    ]\n",
    ")\n",
    "y = np.array(\n",
    "    [\n",
    "        [0],\n",
    "        [2],\n",
    "        [1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"shifter\", SubtractMeanAndShiftTransformer(shift=5)),\n",
    "        (\"regressor\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "y_pred = pipeline.predict(X)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline хранит последовательные Estimators в аттрибуте `steps`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейти к объекту i-го Estimator можно напрямую через `pipeline[i]`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline[1].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как Pipeline сам является Estimator, мы можем увидеть список его параметров:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, параметры промежуточных Estimator указаны как `<estimator>__<parameter>`. Следовательно, мы можем изменить параметры любого промежуточного Estimator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_params(shifter__shift=10)\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте пайплайн по преобразованию численных столбцов, содержащий импьютер и скейлер.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[(\"num\", pipeline, selector(dtype_include=\"number\"))],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "transformer.set_output(transform=\"pandas\")\n",
    "transformer.fit(df)\n",
    "df_transform = transformer.transform(df)\n",
    "\n",
    "print(df_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте новый трансформер, который для категориальных столбцов будет заполнять пропущенные значения наиболее часто встречаюмшщимся или новой категорией (сделайте параметром).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy=\"most_frequent\", fill_value=\"Unknown\"):\n",
    "        self.strategy = strategy\n",
    "        self.fill_value = fill_value\n",
    "        self.imputer = None\n",
    "        self.feature_names_out_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.strategy == \"most_frequent\":\n",
    "            self.imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        else:\n",
    "            self.imputer = SimpleImputer(\n",
    "                strategy=\"constant\", fill_value=self.fill_value\n",
    "            )\n",
    "\n",
    "        self.imputer.fit(X)\n",
    "        self.feature_names_out_ = X.columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_imputed = self.imputer.transform(X)\n",
    "        return pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.feature_names_out_)\n",
    "\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", CategoricalImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[(\"cat\", categorical_pipeline, selector(dtype_exclude=\"number\"))],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "df_transform = transformer.fit_transform(df)\n",
    "df_transform = pd.DataFrame(df_transform, columns=transformer.get_feature_names_out())\n",
    "print(df_transform)\n",
    "\n",
    "categorical_pipeline_most_frequent = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", CategoricalImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_pipeline_most_frequent, selector(dtype_exclude=\"number\"))\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "df_transform = transformer.fit_transform(df)\n",
    "df_transform = pd.DataFrame(df_transform, columns=transformer.get_feature_names_out())\n",
    "print(df_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте пайплайн по преобразованию категориальных столбцов, содержащий ваш импьютер и OneHotEncoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", CategoricalImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[(\"cat\", categorical_pipeline, selector(dtype_exclude=\"number\"))],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "df_transform = transformer.fit_transform(df)\n",
    "df_transform = pd.DataFrame(df_transform, columns=transformer.get_feature_names_out())\n",
    "print(df_transform.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте ColumnTransformer, который будет содержать в себе два вышеуказанных пайплайна.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline = Pipeline(\n",
    "    [(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", CategoricalImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipeline, selector(dtype_include=\"number\")),\n",
    "        (\"cat\", categorical_pipeline, selector(dtype_exclude=\"number\")),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "transformer.set_output(transform=\"pandas\")\n",
    "df_transform = transformer.fit_transform(df)\n",
    "print(df_transform.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Доп.задание**: Используйте для комбинации результатов двух отдельных трансформеров FeatureUnion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
